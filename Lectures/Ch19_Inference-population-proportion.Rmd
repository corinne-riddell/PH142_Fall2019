---
title: "Chapter 19: Inference about a population proportion"
author: "Corinne Riddell"
date: "October 30, 2019"
output: pdf_document
---

### Recap

- So far we've learned the z-test and the t-test that apply when the variable of
interest is continuous
- We applied these tests to one-sample (e.g., $H_0: \mu=8$) and two-sample settings (e.g., $H_0: \mu_1 = \mu_2$)
- Today, we will generalize these procedures to binary data, for which we estimate
a proportion $\hat{p}$ from a sample and use that as our best guess of the 
underlying population parameter $p$
- A note on notation: $\bar{x}$ is to $\mu$ as $\hat{p}$ is to $p$

### Agenda

- Confidence interval for a proportion
- Sample size estimates for a proportion 
- Hypothesis tests for a proportion

### Recall the sampling distribution for $\hat{p}$

The sampling distribution for $\hat{p}$ is centered on $p$ with a standard 
error of $\sqrt{\frac{p(1-p)}{n}}$

If we follow the same format for the CI from previous chapters we would get:

$$\hat{p} \pm z^* \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$$
This is the **large sample confidence interval for a population proportion**

### But...

- This confidence interval does not perform well, meaning that even if you think 
you should have 95% "confidence" that the CI contains the true value $p$, it is 
very often much lower. 
- This means that if you were to use this method across
100 samples and if all the conditions to use the method were true, less than 95 
of them would contain the true parameter $p$

### Introducing: the "Plus 4 method"

- However, there is an easy trick that saves the CI.

- If you add 2 imaginary successes and 2 failures to the dataset (increasing the 
sample size by 4 imaginary trials), the interval performs well again.

- Let $\tilde{p} = \frac{\text{number of successes + 2}}{n+4}$
- Let $SE = \sqrt{\frac{\tilde{p}(1-\tilde{p})}{n+4}}$
- Then the CI is: $$\tilde{p} \pm z^* \sqrt{\frac{\tilde{p}(1-\tilde{p})}{n+4}}$$

- This is called the **"plus four method"**
- Note we use $z^*$ rather than $t^*$. This is because the standard error of 
the sampling distribution is completely determined by $p$ and $n$, we don't need
to estimate a second parameter. Because of this we stay in the land of z scores.
- Use this method when $n$ is at least 10 and the confidence level is at least 
90%

### Why does the plus four method work?

- It is a simplification of a more complex method known as the Wilson Score 
Interval. 

- You don't need to know why it works, just that it is better to use this 
"plus four" trick if you're making a confidence interval for a proportion by hand.

### Two methods so far...

We have so far introduced the large sample method to calculate the CI for p:

$$\hat{p} \pm z^* \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$$
And the plus four method to calculate the CI for p:

- $\tilde{p} = \frac{\text{number of successes + 2}}{n+4}$
- Let $SE = \sqrt{\frac{\tilde{p}(1-\tilde{p})}{n+4}}$
- Then the CI is: $$\tilde{p} \pm z^* \sqrt{\frac{\tilde{p}(1-\tilde{p})}{n+4}}$$

We are going to talk about two more methods.

### What does R use?

- R has two functions to calculate confidence intervals for proportions.

- The first function is `prop.test` (analogous to `t.test`) to calculate confidence intervals and hypothesis tests for binomial proportions. 

- This function uses the "Wilson score interval with a continuity correction".
Thus, when you use the `prop.test` function, you don't need to "plus 4", it 
will do it for you (and does an even better job because of the continuity
correction.) 

- `prop.test()` corresponds to the **Wilson score** method. You do not need to 
know how to calculate the Wilson score method by hand. You only need to know 
how to use R to perform this method.

### What does R use?
    
- There is a fourth method to compute confidence intervals for proportions that 
is often used called the **Clopper Pearson method**, also known as the 
**"Exact method"**. It is implemented with the R function `binom.test()`

- The exact method is statistically conservative, meaning that it gives better
coverage than it suggests. That is, a 95% CI computed under this method includes
the true proportion in the interval more than 95% of the time.

### Example applying all the methods

Suppose that 500 elderly individuals suffered hip fractures, of which
100 died within a year of their fracture. Compute the 95% CI for the proportion
who died using:

- the large sample method, 
- the plus for method (by hand),
- the Wilson Score method (using `prop.test`), 
- the Clopper Pearson Exact method (using `binom.test`)

### Example of large sample method to calculate the CI for a proportion (by hand)

```{r}
p.hat <- 100/500 # estimate proportion
se <- sqrt(p.hat*(1-p.hat)/500) # standard error
p.hat - 1.96*se # Lower confidence bound
p.hat + 1.96*se # Upper confidence bound
```

Our estimate for the proportion is $\hat{p}=20\%$. Using the large sample method,
the 95% confidence interval is 16.5% to 23.5%. Remember, this method has poor 
coverage, meaning that less than 95 of the 100 intervals we could make would contain the true
value $p$.

### Example using the Clopper Pearson "Exact" method to calculate the CI for a proportion (using R)

```{r}
binom.test(x = 100, n = 500, conf.level = 0.95)
```

- The 95% confidence interval using the exact binomial test is 16.6% to 23.8%.
- Note that this interval is wider than the one made with the large sample method.
This is because it has better coverage (contains the true value more often) which
necessitates a wider interval.
- Note that the `binom.test` function is also conducting a two-sided hypothesis 
test (where $H_0: p_0=0.5$, unless otherwise specified). You can ignore the 
testing-related output and focus on the CI output when using the function to 
make a CI. 

### Example using the Wilson Score method to calculate the CI for a proportion (using R)

```{r}
prop.test(x = 100, n = 500, conf.level = 0.95)
```

- The 95% confidence interval using the Wilson Score method is 16.6% to 23.8%.
- Note that the `prop.test` function is also conducting a two-sided hypothesis 
test (where $H_0: p_0=0.5$, unless otherwise specified). You can ignore the 
testing-related output and focus on the CI output when using the function to 
make a CI. 

### Example using the plus 4 method to calculate the CI for a proportion (by hand)

```{r plus-four}
p.tilde <- (100 + 2)/(500 + 4)
se <- sqrt(p.tilde * (1 - p.tilde)/504) # standard error
p.tilde - 1.96 * se # Lower confidence bound
p.tilde + 1.96 * se # Upper confidence bound
```

Using the plus 4 method, the confidence interval is 16.7% to 23.7%.

### Summary of the confidence intervals across the methods

| Method       | 95% Confidence Interval | R Function       |
|:------------:|:-----------------------:|:----------:|
| Large sample | 16.5% to 23.5%          | by hand      |
| Clopper Pearson*| 16.6% to 23.8%          | `binom.test` |
| Wilson Score** | 16.6% to 23.8%          | `prop.test`  |
| Plus four    | 16.7% to 23.7%          | by hand      |

*also known as the exact method

**with continuity correction

- Only the large sample method is symmetric around $\hat{p} = 20\%$. This is
okay. There is no reason why we require a symmetric confidence interval. But note the 
CIs we made for means in the continuous setting had symmetric CIs.
- Non-symmetric CIs make sense because $p$ is bounded between 0 and 1. For example, if
$p$ is very small, say 0.012, you would not want a CI that has a lower bound which is 
negative, this would not make sense.
- When the Normal approximation assumptions are satisfied, the methods give very
similar results.

### Another example of the Plus Four method (by hand)

I'm including another example for you to read so you can practice working out 
the calculations by hand.

A study examined a random sample of 75 SARS patients, of which 64 developed 
recurrent fever.

Therefore $\hat{p}=64/75=85.33\%$

Using the plus 4 method: $\tilde{p}=\frac{64 + 2}{75+4} = 83.54\%$

$$SE=\sqrt{\frac{\tilde{p}(1-\tilde{p})}{75+4}}=\sqrt\frac{{.8354\times {(1- 0.8354)}}}{79} = 0.04172$$
Thus the plus four 95% CI is: $\tilde{p} \pm 1.96 \times SE = 0.8354 \pm 0.04172 = 79.37\% \text{ to } 87.71\%$


### How big should the sample be to estimate a proportion?

Suppose that you want to estimate a sample size for a proportion within a given
margin of error. That is, you want to put a maximum bound on the width of the 
corresponding confidence interval.

Let $m$ denote the desired margin of error. Then $m = z^*\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$

We can solve this equation for $n$, but we also need to plug in a value for $p$. 
To do that we make a guess for $p$ denoted by $p^*$. 

$p^*$ is your best estimate for the underlying proportion. You might gather this
estimate from a completed pilot study or based on previous studies published by
someone else. If you have no best guess, you can use $p^*=0.5$. This will produce
the most conservative estimate of $n$. However if the true $p$ is less than 0.3
or greater than 0.7, the sample size estimated may be much larger than you need.



### How big should the sample be to estimate a proportion?

Rearranging the formula on the last slide for $n$, we get:

$m = z^*\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$

$\sqrt{n}m=z^*\sqrt{p(1-p)}$

$\sqrt{n}=\frac{z^*}{m}\sqrt{p(1-p)}$

$n = (\frac{z^*}{m})^2p^*(1-p^*)$

This last formula is the one we will use to estimate the required sample size.

### Example of estimating sample size

Suppose after the midterm vote, you were interested in estimating the number of 
STEM undergraduate students who voted. First you need to decide what margin of error
you desire. Suppose it is 4 percentage points or $m=0.04$ for a 95% CI.

If you had no idea what proportion of STEM students voted then you let $p^*=0.5$
and solve for $n$:

$n = (\frac{z^*}{m})^2p^*(1-p^*) = (\frac{1.96}{0.04})^2\times 0.5 \times 0.5 = 600.25 = 601$

However, suppose you found a previous study that estimated the number of STEM students
who voted to be 25%. Then what sample size would you need to detect this proportion?

$n = (\frac{z^*}{m})^2p^*(1-p^*) = (\frac{1.96}{0.04})^2\times 0.25 \times 0.75 = 450.19 = 451$

### Example of estimating sample size

What if you want the width of the 95% confidence interval to be 6 percentage 
points. What would $m$ be in this case?

### Example of estimating sample size

What if you want the width of the 95% confidence interval to be 6 percentage 
points. What would $m$ be in this case?

The width of the 95% CI is equal to twice the margin of error. So if you want the
width to be 0.06, then this is equivalent to saying you want a margin of error
of 0.03.

### Hypothesis tests of a proportion

When you only have one sample what is the null hypothesis? You're interested in
knowing whether there is evidence against the null hypothesis that the population
proportion $p$ is equal to some specified value $p_0$. That is:

$$H_0: p = p_0$$

For example, you may want to test whether there is evidence against the 
null hypothesis that $p = 0.25$.

### Hypothesis tests of a proportion

Recall the sampling distribution for the proportion:

- Normally distributed
- Centred at $p_0$ under the null distribution
- Has a standard error of $\sqrt{\frac{p_0(1-p_0)}{n}}$

### Hypothesis tests of a proportion

The test statistic for the null hypothesis is:

$$z = \frac{\hat{p}-p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}}$$
This is a z-test (not a t-test) so we compared to the standard Normal distribution
and ask what is the probability of observing a $z$ value of this magnitude (or
more extreme).

### Hypothesis tests of a proportion

One sided alternatives:

- $H_a: p > p_0$ 
- $H_a: p < p_0$

Two-sided alternative:

- $H_a: p \ne p_0$

When to use this test? Use this test when the expected number of successes and 
failures is $\geq$ 10. That is, when $np_0\geq10$ and $n(1-p_0)\geq 10$.

### Example of a hypothesis test for a proportion

Consider a SRS of 200 patients undergoing treatment to alleviate side effects 
from a rigorous drug regimen at a particular hospital, where 33 patients 
experienced reduced or no side effects. 

$\hat{p}=33/200=0.165=16.5\%$

Suppose that historically, the rate of patients with little or no side effects is
10%. Does the new treatment increase the rate? That is:

$H_0: p = 0.10$ 

$H_a: p > 0.10$

### Example of a hypothesis test for a proportion

Step 1: Calculate $\hat{p} = 16.5\%$ from previous slide.

Step 2: Calculate the standard error of the sampling distribution for $p$ under
the null hypothesis: $SE = \frac{\sqrt{p_0(1-p_0)}}{n} = \frac{\sqrt{0.1(1-0.1)}}{200} = 0.0212132$

Step 3: Calculate the z-test for the proportion:

$z = \frac{\hat{p}-p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}} = \frac{0.165-0.10}{0.0212132} = 3.06413$

Step 4: Calculate the probability of seeing a z-value of this magnitude *or larger*:

```{r}
pnorm(q = 3.06413, lower.tail = F)
```

Step 5: Evaluate the evidence against the null hypothesis. Because the p-value is 
so small (0.1%), there is little chance of seeing a proportion equal to 16.5%
or larger if the true proportion is actually 10%. Thus, there is evidence in 
favor of the alternative hypothesis, that the underlying proportion is larger
than 10%.

### Example to try at home

Suppose that there were 100 elderly individuals with falls observed, and 2 died.
Here are the 95% CIs applying the four different methods:

| Method       | 95% Confidence Interval | R Function       |
|--------------|:-----------------------:|--------------|
| Large sample | -0.74% to 4.74%          | by hand      |
| Exact        | 0.024% to 7.04%          | `binom.test` |
| Wilson Score* | 0.034% to 7.74%          | `prop.test`  |
| Plus four    | 0.15% to 7.54%           | by hand      |

*with continuity correction

### Example to try at home

We can graphically compare the CIs from the previous slide:

```{r, echo=F, fig.align='center', out.width="80%"}
# students, dont worry about this code
library(ggplot2)
library(tibble)
elderly_CIs <- tibble(method = c("large sample", "Exact", "Wilson", "Plus 4"),
       lower = c(-0.74, 0.024, 0.034, 0.15),
       upper = c(4.74, 7.04, 7.74, 7.54),
       estimate = rep(2,4))

ggplot(data = elderly_CIs, 
       aes(x = method, y = estimate)) +
  geom_point() +
  geom_segment(aes(xend = method, y = lower, yend = upper)) +
  geom_hline(aes(yintercept = 0), lty = 2) +
  labs(y = "Estimate and 95% CI", x = "") +
  theme_minimal(base_size = 15)
```

### Example to try at home

Findings:

- Notice how different the intervals are, especially large sample vs. others. 
- Notice that the large sample lower bound is non-sensical (i.e., we can't have negative proportions!)
- The large sample CI differs from the others because the Normal approximation assumptions
are not satisfied.

### Example to try at home

- We won't go through the code below in class, but here is the code to arrive
at the estimates for the previous table:

```{r large-sample}
p.hat <- 2/100 # estimate proportion
se <- sqrt(p.hat*(1-p.hat)/100) # standard error
c(p.hat - 1.96*se, p.hat + 1.96*se) # CI
```
```{r exact-method}
binom.test(x = 2, n = 100, p = 0.5, conf.level = 0.95)
```

```{r wilson-score}
prop.test(x = 2, n = 100, p = 0.5, conf.level = 0.95)
```

```{r plus-4-method}
p.tilde <- (2 + 2)/(100 + 4)
se <- sqrt(p.tilde*(1-p.tilde)/104) # standard error
c(p.tilde - 1.96*se, p.tilde + 1.96*se) # CI
```

